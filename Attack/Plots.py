"""
# Plots codes are generated by chatgpt 3.5


import matplotlib.pyplot as plt
import numpy as np

def one_plot():
    # Data
    attack_types = ['Attack Type 1', 'Attack Type 2']
    accuracy = [0.59, 0.5436]
    f1_score = [0.55, 0.6117]

    # Plot setup
    x = np.arange(len(attack_types))  # the label locations
    width = 0.35  # the width of the bars

    fig, ax = plt.subplots()
    bars1 = ax.bar(x - width/2, accuracy, width, label='Accuracy')
    bars2 = ax.bar(x + width/2, f1_score, width, label='F1-score')

    # Add some text for labels, title and custom x-axis tick labels, etc.
    ax.set_xlabel('Attack Type')
    ax.set_ylabel('Scores')
    ax.set_title('Performance Metrics by Attack Type')
    ax.set_xticks(x)
    ax.set_xticklabels(attack_types)
    ax.legend()

    # Add labels above the bars
    def add_labels(bars):
        for bar in bars:
            height = bar.get_height()
            ax.annotate(f'{height:.2f}',
                        xy=(bar.get_x() + bar.get_width() / 2, height),
                        xytext=(0, 3),  # 3 points vertical offset
                        textcoords="offset points",
                        ha='center', va='bottom')

    add_labels(bars1)
    add_labels(bars2)

    fig.tight_layout()

    # Save the plot as a PDF
    plt.savefig('performance_metrics_by_attack_type_Duke.pdf', format='pdf')

def two_plot():
    import matplotlib.pyplot as plt
    import numpy as np

    # Data
    attack_types = ['Attack Type 1', 'Attack Type 2']
    accuracy_nested_unets = [0.59, 0.5436]
    f1_score_nested_unets = [0.55, 0.6117]
    accuracy_unet = [0.6, 0.46]
    f1_score_unet = [0.6532, 0.3367]
    # Plot setup
    x = np.arange(len(attack_types))  # the label locations
    width = 0.35  # the width of the bars

    # Accuracy plot
    fig, ax = plt.subplots()
    bars1 = ax.bar(x - width / 2, accuracy_nested_unets, width, label='Nested Unets')
    bars2 = ax.bar(x + width / 2, accuracy_unet, width, label='Unet')

    # Add some text for labels, title and custom x-axis tick labels, etc.
    ax.set_xlabel('Attack Type')
    ax.set_ylabel('Accuracy')
    ax.set_title('Accuracy by Attack Type')
    ax.set_xticks(x)
    ax.set_xticklabels(attack_types)
    ax.legend()

    # Add labels above the bars
    def add_labels(bars):
        for bar in bars:
            height = bar.get_height()
            ax.annotate(f'{height:.2f}',
                        xy=(bar.get_x() + bar.get_width() / 2, height),
                        xytext=(0, 3),  # 3 points vertical offset
                        textcoords="offset points",
                        ha='center', va='bottom')

    add_labels(bars1)
    add_labels(bars2)

    fig.tight_layout()
    # Save the accuracy plot as a PDF
    plt.savefig('accuracy_by_attack_type_Duke.pdf', format='pdf')
    plt.show()

    # F1-score plot
    fig, ax = plt.subplots()
    bars1 = ax.bar(x - width / 2, f1_score_nested_unets, width, label='Nested Unets')
    bars2 = ax.bar(x + width / 2, f1_score_unet, width, label='Unet')

    # Add some text for labels, title and custom x-axis tick labels, etc.
    ax.set_xlabel('Attack Type')
    ax.set_ylabel('F1-score')
    ax.set_title('F1-score by Attack Type')
    ax.set_xticks(x)
    ax.set_xticklabels(attack_types)
    ax.legend()

    # Add labels above the bars
    add_labels(bars1)
    add_labels(bars2)

    fig.tight_layout()
    # Save the F1-score plot as a PDF
    plt.savefig('f1_score_by_attack_type_Duke.pdf', format='pdf')



#two_plot()


import matplotlib.pyplot as plt
import numpy as np

# Data for plotting
models = ["Duke/UNet", "Duke/NestedUNet", "UMN/NestedUNet", "UMN/UNet"]
accuracy = [0.5, 0.5, 0.5806, 0.5968]
f_score = [0.6667, 0.6667, 0.4583, 0.5455]

tn = [0, 0, 25, 22]
fp = [5, 5, 6, 9]
fn = [0, 0, 20, 16]
tp = [5, 5, 11, 15]

# Create subplots
fig, axs = plt.subplots(2, 2, figsize=(14, 10))

# Accuracy plot
axs[0, 0].bar(models, accuracy, color='b')
axs[0, 0].set_title('Validation Accuracy')
axs[0, 0].set_ylabel('Accuracy')

# F-score plot
axs[0, 1].bar(models, f_score, color='g')
axs[0, 1].set_title('F-score')
axs[0, 1].set_ylabel('F-score')


x = np.arange(len(models))
width = 0.35
axs[1, 0].bar(x - width/2, tn, width, label='TN', color='c')
axs[1, 0].bar(x + width/2, fp, width, label='FP', color='m')
axs[1, 0].set_title('True Negatives and False Positives')
axs[1, 0].set_ylabel('Count')
axs[1, 0].set_xticks(x)
axs[1, 0].set_xticklabels(models)
axs[1, 0].legend()

axs[1, 1].bar(x - width/2, fn, width, label='FN', color='y')
axs[1, 1].bar(x + width/2, tp, width, label='TP', color='r')
axs[1, 1].set_title('False Negatives and True Positives')
axs[1, 1].set_ylabel('Count')
axs[1, 1].set_xticks(x)
axs[1, 1].set_xticklabels(models)
axs[1, 1].legend()

plt.tight_layout()
plt.show()

"""
from modulefinder import Module

from numpy.core.defchararray import endswith

"""from PIL import Image
import numpy as np

array= np.asarray(Image.open('DME/DME-15307-1.jpeg'))
print(type(array))

array= np.load("DukeData/test/images/Subject_09_00.npy")
print(type(array))"""

""""""
"""import pandas as pd

import os

# Load the dataset
file_path = 'true_vs_pred_labels.csv'
data = pd.read_csv(file_path)

# Filter the rows based on the condition
filtered_data = data[data['sample_names'] == 'DukeData_synthetic_True_1_multiple_shadowTrue']

# Combine all the values in the 'true_labels' column into a single list
combined_true_labels = [float(label) for label in filtered_data['true_labels']]
combined_predictions= [float(label) for label in filtered_data['pred_labels_roc']]


new_row = {
    'sample_names': 'DukeData_synthetic_True_1_multiple_shadowTrue',
    'true_labels': [combined_true_labels],
    'pred_labels_roc': [combined_predictions],
    'ATTACK_BATCH_SIZE':[16]
}
new_row_df = pd.DataFrame(new_row)

df = pd.concat([data, new_row_df], ignore_index=True)

# Define the filename for the CSV file
filename = 'test_csv.csv'

# Check if the file already exists and append or create a new one
if os.path.exists(filename):
    # Append to the file if it exists, without writing the header again
    df.to_csv(filename, mode='a', header=False, index=False)
else:
    # If the file doesn't exist, create it and write the header
    df.to_csv(filename, mode='w', header=True, index=False)

print("New row added and CSV file updated successfully!")"""

"""
import matplotlib.pyplot as plt

# Data for each of the entries
data = {
    "a": {"training_loss": 0.7582190598939594, "validation_loss": 0.7586227655410767},
    "b": {"training_loss": 0.2593105195070568, "validation_loss": 0.2681558086321904},
    "c": {"training_loss": 0.663378677368164, "validation_loss": 0.663168572462522},
}

# Extracting the losses
training_losses = [data['a']['training_loss'], data['b']['training_loss'], data['c']['training_loss']]
validation_losses = [data['a']['validation_loss'], data['b']['validation_loss'], data['c']['validation_loss']]

# Plotting
plt.figure(figsize=(10, 6))

# Plot for training losses
plt.plot(['a', 'b', 'c'], training_losses, label="Training Loss", marker='o')

# Plot for validation losses
plt.plot(['a', 'b', 'c'], validation_losses, label="Validation Loss", marker='s')

# Adding labels and title
plt.xlabel("Dataset")
plt.ylabel("Loss")
plt.title("Training and Validation Losses for Models a, b, and c")
plt.legend()

# Show plot
plt.grid(True)
plt.show()
"""
from networks import get_model
import torch
import numpy as np
import matplotlib.pyplot as plt
import torchvision.transforms as transforms
import os
# Custom transformations from your previous code
class TransformStandardization(object):
    def __init__(self, mean, std):
        self.mean = mean
        self.std = std

    def __call__(self, image):
        return (image - self.mean) / self.std

class TransformOCTMaskAdjustment(object):
    def __call__(self, mask):
        mask[mask == 8] = 0
        mask[mask == 9] = 8

        return mask


class TransformOCTMaskAdjustment_Separate(object):
    """
    Adjust OCT 2015 Mask
    from: classes [0,1,2,3,4,5,6,7,8,9], where 9 is fluid, 0 is empty space above and 8 empty space below
    to: class 0: not class, classes 1-7: are retinal layers, class 8: fluid
    """

    def __call__(self, mask,i):
        #mask = (mask == i).astype(int)
        #mask[mask == 8] = 0
        #mask[mask == 9] = 8
        mask[mask != i] = 0
        mask[mask == i] = 1
        return mask

class TransformOCTBilinear(object):
    def __init__(self, img_size=(128, 128), n_channels=None):
        self.img_size = img_size
        self.n_channels = n_channels
        self.resize_transform = transforms.Resize(self.img_size, interpolation=transforms.InterpolationMode.BILINEAR)

    def __call__(self, img):
        # Check and handle the number of channels
        if img.mode == 'RGBA':  # Assuming img is a PIL.Image
            # Convert RGBA to RGB by discarding the alpha channel
            img = img.convert('RGB')

        # Apply resizing
        img = self.resize_transform(img)

        # Optionally adjust the number of channels if specifically required
        if self.n_channels == 1:
            # Convert to grayscale (this would now operate on RGB images)
            img = transforms.Grayscale(num_output_channels=1)(img)
        elif self.n_channels == 3 and img.mode != 'RGB':
            # Ensure it is in RGB format
            img = img.convert('RGB')

        return img
def load_model(model_path, model_name, num_classes, device="cpu"):
    model_path=os.path.join("/home/parsar0000/oct_git/main_code/saved_models", model_path)
    model = get_model(model_name, num_classes=num_classes).to(device)
    checkpoint = torch.load(model_path)
    state_dict = checkpoint['model_state_dict']
    # Strip the `_module.` prefix if it exists
    new_state_dict = {}
    for key in state_dict.keys():
        new_key = key.replace('_module.', '')  # Remove the _module prefix
        new_state_dict[new_key] = state_dict[key]
    model.load_state_dict(new_state_dict)
    model.eval()  # Set the model to evaluation mode
    return model


def preprocess_image_mask(image_path, mask_path,i, img_size):
    # Load image from .npy file
    img = np.load(image_path)
    mask = np.load(mask_path)

    # Ensure the image has 2D dimensions (height, width)
    img = torch.Tensor(img).reshape(1, 1, *img.shape)  # Add batch and channel dimensions

    # Reshape mask to be [1, height, width] and cast to long for integer labels
    mask = torch.Tensor(mask).reshape(1, *mask.shape).long()

    # Adjust mask classes
    mask_adjust = TransformOCTMaskAdjustment()
    mask = mask_adjust(mask)
    if i>=0:
        mask_adjust_separate = TransformOCTMaskAdjustment_Separate()
        mask =mask_adjust_separate(mask,i)

    # Resize the image (bilinear) and mask (nearest-neighbor)
    size_transform_img = transforms.Resize((img_size, img_size), interpolation=transforms.InterpolationMode.BILINEAR)
    size_transform_mask = transforms.Resize((img_size, img_size), interpolation=transforms.InterpolationMode.NEAREST)

    img = size_transform_img(img)  # Resize the image using bilinear interpolation
    mask = size_transform_mask(mask)  # Resize the mask using nearest-neighbor interpolation

    # Normalize the image
    normalize = TransformStandardization(mean=46.3758, std=53.9434)
    img = normalize(img)

    return img, mask



# Function to infer the mask from the model
def infer_image(model, image, device="cpu"):
    image = image.to(device)
    with torch.no_grad():
        output = model(image)
        _, predicted_mask = torch.max(output, 1)
    return predicted_mask



models=["unet_UMN.pt","unet_UMN_DPSGD_8.0.pt","y_net_gen_UMN.pt","y_net_gen_UMN_DPSGD_8.0.pt","LFUNet_UMN.pt","LFUNet_UMN_DPSGD_8.0.pt","FCN8s_UMN.pt","FCN8s_UMN_DPSGD_8.0.pt",
        "NestedUNet_UMN.pt","NestedUNet_UMN_DPSGD_8.0.pt"]
normal_models = [model for model in models if "DPSGD" not in model]
dpsgd_models = [model for model in models if "DPSGD" in model]
# Example model names (just for display in the plot)
model_names = ["unet", "y_net_gen", 'LFUNet', 'FCN8s',
                                 'NestedUNet']




def create_overlay(img, mask, layer_colors):
    # Ensure mask is 2D by squeezing any singleton dimensions
    mask = mask.squeeze()  # Remove any singleton dimensions, so mask has shape [height, width]
    # Initialize an empty overlay with the same height and width as the mask, and 3 color channels (RGB)
    overlay = np.zeros((mask.shape[0], mask.shape[1], 3))
    # Assign colors based on the mask values
    for value, color in layer_colors.items():
        overlay[mask == value] = color

    return overlay

def generate_model_results(model_path,model_name,image_path, mask_path, img_size,num_classes=2):
    img,mask=preprocess_image_mask(image_path,mask_path, img_size)
    # load model
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = load_model(model_path, model_name=model_name, num_classes=num_classes, device=device)
    predicted_mask= infer_image(model, img, device)

    img=img.cpu().numpy().squeeze()
    msk=mask.cpu().numpy().squeeze()
    predicted_mask=predicted_mask.cpu().numpy()
    # Define colors for each layer (RGB tuples)

    layer_colors = {
        0: (0, 0, 0),  # Black for the modified 0
        1: (1, 0, 0),  # Red
        2: (0, 1, 0),  # Green
        3: (0, 0, 1),  # Blue
        4: (1, 1, 0),  # Yellow
        5: (1, 0, 1),  # Magenta
        6: (0, 1, 1),  # Cyan
        7: (1, 0.5, 0),  # Orange
        8: (0.8, 0.7, 0.6)  # Light Brown
    }
    true_overlay = create_overlay(img, msk, layer_colors)
    predicted_overlay = create_overlay(img, predicted_mask, layer_colors)

    original_rgb = np.stack([img] * 3, axis=-1)
    min_val = original_rgb.min()
    max_val = original_rgb.max()
    # Normalize based on observed min and max
    original_rgb = (original_rgb - min_val) / (max_val - min_val)

    true_combined = np.clip(0.7 * original_rgb + 0.3 * true_overlay, 0, 1)
    predicted_combined = np.clip(0.7 * original_rgb + 0.3 * predicted_overlay, 0, 1)

    return original_rgb, predicted_combined

def plot_comparison_grid(normal_models, dpsgd_models, model_names,image_path,mask_path):
    num_models = len(model_names)
    fig, axes = plt.subplots(2, num_models, figsize=(15, 6))
    for i, model_path in enumerate(normal_models):
        model_name = model_names[i]
        print(model_name)
        original_rgb, predicted_combined = generate_model_results(model_path, model_name, image_path, mask_path,
                                                                  img_size=224)
        # Plot original image (top row)
        axes[0, i].imshow(predicted_combined)
        axes[0, i].set_title(model_name)
        axes[0, i].set_xticks([])
        axes[0, i].set_yticks([])
        axes[0, i].axis('off')

    for i, dpsgd_model_path in enumerate(dpsgd_models):
        model_name = model_names[i]
        original_rgb, predicted_combined = generate_model_results(dpsgd_model_path, model_name, image_path,mask_path,img_size=224)
        axes[1, i].imshow(predicted_combined)
        axes[1, i].set_title(model_name)
        axes[1, i].set_xticks([])
        axes[1, i].set_yticks([])
        axes[1, i].axis('off')
        # Set row labels
    """axes[0, 0].annotate('Without DPSGD', xy=(-0.2, 0.5), xytext=(-axes[0, 0].yaxis.labelpad - 5, 0),
                        xycoords=axes[0, 0].yaxis.label, textcoords='offset points',
                        ha='center', va='center', rotation=90, fontsize=14, color='black')
    axes[1, 0].annotate('With DPSGD', xy=(-0.2, 0.5), xytext=(-axes[1, 0].yaxis.labelpad - 5, 0),
                        xycoords=axes[1, 0].yaxis.label, textcoords='offset points',
                        ha='center', va='center', rotation=90, fontsize=14, color='black')"""

    fig.text(0.5, 0.92, 'Without DPSGD', ha='center', va='center', fontsize=14, color='black')
    fig.text(0.5, 0.46, 'With DPSGD', ha='center', va='center', fontsize=14, color='black')

    plt.tight_layout()
    plt.show()





def plot_image_mask(image_path, mask_path,i=-1):
    img, mask = preprocess_image_mask(image_path, mask_path,i, img_size=224)
    img = img.cpu().numpy().squeeze()
    msk = mask.cpu().numpy().squeeze()
    layer_colors = {
        0: (0, 0, 0),  # Black for the modified 0
        1: (1, 0, 0),  # Red
        2: (0, 1, 0),  # Green
        3: (0, 0, 1),  # Blue
        4: (1, 1, 0),  # Yellow
        5: (1, 0, 1),  # Magenta
        6: (0, 1, 1),  # Cyan
        7: (1, 0.5, 0),  # Orange
        8: (0.8, 0.7, 0.6)  # Light Brown
    }
    true_overlay = create_overlay(img, msk, layer_colors)
    original_rgb = np.stack([img] * 3, axis=-1)
    min_val = original_rgb.min()
    max_val = original_rgb.max()
    # Normalize based on observed min and max
    original_rgb = (original_rgb - min_val) / (max_val - min_val)
    true_combined = np.clip(0.7 * original_rgb + 0.3 * true_overlay, 0, 1)
    fig, axes = plt.subplots(2, 1, figsize=(8, 4))
    axes[0].imshow(original_rgb)
    axes[0].set_title("Original Image")
    axes[0].set_xticks([])
    axes[0].set_yticks([])
    axes[0].axis('off')

    axes[1].imshow(true_combined)
    axes[1].set_title("True Mask")
    axes[1].set_xticks([])
    axes[1].set_yticks([])
    axes[1].axis('off')
    plt.tight_layout()
    plt.show()



image_dir="/home/parsar0000/oct_git/UMNData/test/images"
mask_dir="/home/parsar0000/oct_git/UMNData/test/masks"
image_filenames = sorted(os.listdir(image_dir))
mask_filenames = sorted(os.listdir(mask_dir))
image_filenames=[f for f in image_filenames if f.endswith(".npy")]
mask_filenames=[f for f in mask_filenames if f.endswith(".npy")]
# activate this part if you need results and also raw image and its mask
"""for img_path, mask_path in zip(image_filenames, mask_filenames):
    img_path=os.path.join(image_dir, img_path)
    mask_path=os.path.join(mask_dir, mask_path)
    plot_image_mask(img_path,mask_path)
    #plot_comparison_grid(normal_models, dpsgd_models, model_names,img_path,mask_path)"""


from PIL import Image
def plot_side_by_side():

    image_left = Image.open("../../Documentation/Images/umn_sample2.png")
    image_right = Image.open("../../Documentation/Images/sample_UMN_results.png")

    # Define white space between the images
    white_space = 0

    # Resize the left-side image (increase its size)
    left_scale_factor = 1.5  # Adjust to make the left image larger or smaller
    new_left_size = (int(image_left.width * left_scale_factor), int(image_left.height * left_scale_factor))
    image_left_resized = image_left.resize(new_left_size)

    # Resize the right image if needed (keeping it the same in this case)
    scale_factor = 1.0 # Adjust the scale if needed
    new_right_size = (int(image_right.width * scale_factor), int(image_right.height * scale_factor))
    image_right_resized = image_right.resize(new_right_size)


    # Calculate total width and maximum height
    total_width = image_left_resized.width + image_right_resized.width + white_space
    max_height = max(image_left_resized.height, image_right_resized.height)

    # Create a new blank image with a white background
    new_image = Image.new('RGB', (total_width, max_height), (255, 255, 255))

    # Compute vertical offset to align the left image with the right image
    vertical_offset = (max_height - image_left_resized.height) // 2

    # Paste images onto the new canvas
    new_image.paste(image_left_resized, (0, vertical_offset))
    new_image.paste(image_right_resized, (image_left_resized.width + white_space, 0))
    bbox = new_image.getbbox()
    new_image_cropped = new_image.crop(bbox)

    # Display the new image without axis numbers
    plt.imshow(new_image)
    plt.xticks([])
    plt.yticks([])
    plt.axis('off')  # This removes both x and y axes
    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)  # Removes any padding around the image
    plt.show()


# Plot different layers

num_classes=9
image_dir="/home/parsar0000/oct_git/DukeData/test/images"
mask_dir="/home/parsar0000/oct_git/DukeData/test/masks"
image_filenames = sorted(os.listdir(image_dir))
mask_filenames = sorted(os.listdir(mask_dir))
image_filenames=[f for f in image_filenames if f.endswith(".npy")]
mask_filenames=[f for f in mask_filenames if f.endswith(".npy")]
for img_path, mask_path in zip(image_filenames, mask_filenames):
    img_path=os.path.join(image_dir, img_path)
    mask_path=os.path.join(mask_dir, mask_path)
    for i in range((num_classes)):
     plot_image_mask(img_path,mask_path,i)
